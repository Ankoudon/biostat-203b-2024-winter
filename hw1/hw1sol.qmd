---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 26, 2024 @ 11:59PM
author: "Hiroyasu Ando, UID: 605948443"
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information for reproducibility:

```{r}
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1.  Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email. You'll get GitHub Pro account for free (unlimited public and private repositories).

    **Answer:**

    I applied for the Student Developer Pack and got GitHub Pro account.

    ![](images/Q1-1.png){width="160"}

2.  Create a **private** repository `biostat-203b-2024-winter` and add `Hua-Zhou` and TA team (`Tomoki-Okuno` for Lec 1; `jonathanhori` and `jasenzhang1` for Lec 80) as your collaborators with write permission.

    **Answer:**

    It's done.

    ![](images/Q1-2.png){width="333"}

3.  Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `main` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `main` branch will be your presentation area. Submit your homework files (Quarto file `qmd`, `html` file converted by Quarto, all code and extra data sets to reproduce results) in the `main` branch.

    **Answer:**

    It's done.

    ![](images/Q1-3.png){width="382"}

4.  After each homework due date, course reader and instructor will check out your `main` branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

    **Answer:**

    Okay.

5.  After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

    **Answer:**

    Okay.

## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data v2.2](https://physionet.org/content/mimiciv/2.2/), a freely accessible critical care database developed by the MIT Lab for Computational Physiology. Follow the instructions at <https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data. Display the verification links to your completion report and completion certificate here. **You must complete Q2 before working on the remaining questions.** (Hint: The CITI training takes a few hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

**Answer:**

(1) Completion report (CITI)

<https://www.citiprogram.org/verify/?k9cad851b-7215-4e9d-84a9-93d8ee84720e-60469675>

(2) Completion certificate (CITI)

<https://www.citiprogram.org/verify/?wfe307642-6687-49de-a08c-4155771715ed-60469675>

(3) PhysioNet credentialing

![](images/Q2.png)

## Q3. Linux Shell Commands

1.  Make the MIMIC v2.2 data available at location `~/mimic`.

```{bash}
ls -l ~/mimic/
```

Refer to the documentation <https://physionet.org/content/mimiciv/2.2/> for details of data files. Please, do **not** put these data files into Git; they are big. Do **not** copy them into your directory. Do **not** decompress the gz data files. These create unnecessary big files and are not big-data-friendly practices. Read from the data folder `~/mimic` directly in following exercises.

Use Bash commands to answer following questions.

2.  Display the contents in the folders `hosp` and `icu` using Bash command `ls -l`. Why are these data files distributed as `.csv.gz` files instead of `.csv` (comma separated values) files? Read the page <https://mimic.mit.edu/docs/iv/> to understand what's in each folder.

**Answer:**

Compressed files take up less storage space than uncompressed files and use less bandwidth when transferred over the network. This is why these data files are distributed as ".csv.gz" files instead of ".csv" files.

**hosp:**

```{bash}
ls -l ~/mimic/hosp
```

**icu:**

```{bash}
ls -l ~/mimic/icu 
```

3.  Briefly describe what Bash commands `zcat`, `zless`, `zmore`, and `zgrep` do.

    **zcat:**

    "zcat" can display the contents of compressed files without actually decompressing it.

    **zless:**

    "zless" can display the contents of compressed files one page at a time. When you scroll down or click down button, it will display the next line.

    **zmore:**

    "zmore" can display the contents of compressed files one page at a time. When you scroll down or click down button, it will display the next page.

    **zgrep:**

    "zgrep" can extract a specific string or pattern within a compressed files without actually decompressing it.

4.  (Looping in Bash) What's the output of the following bash script?

**Answer:**

This shows the file size, file name, and the date and time the file was last modified for each file in the folder "hosp" that starts with "a", "l", or "pa" and ends with ".gz".

```{bash}
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
  do
    ls -l $datafile
  done
```

Display the number of lines in each data file using a similar loop. (Hint: combine linux commands `zcat <` and `wc -l`.)

```{bash}
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
  do
    echo $datafile
    zcat < $datafile | wc -l
  done
```

5.  Display the first few lines of `admissions.csv.gz`. How many rows are in this data file? How many unique patients (identified by `subject_id`) are in this data file? Do they match the number of patients listed in the `patients.csv.gz` file? (Hint: combine Linux commands `zcat <`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and so on.)

**First few lines, admissions.csv.gz:**

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head -n 5
```

**Rows, admissions.csv.gz (including headers):**

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | wc -l
```

**Unique patients, admissions.csv.gz:**

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $1 }' | \
sort | uniq | wc -l
```

**Patients, patients.csv.gz:**

```{bash}
zcat < ~/mimic/hosp/patients.csv.gz | awk -F, 'FNR > 1 { print $1 }' | wc -l
```

**Unique patients, patients.csv.gz:**

```{bash}
zcat < ~/mimic/hosp/patients.csv.gz | awk -F, 'FNR > 1 { print $1 }' |  \
sort | uniq | wc -l
```

**Answer:**

There are 431232 rows in the data file "admissions.csv.gz" (including headers). There are 180733 unique patients in the data file "admissions.csv.gz". They do not match the number of patients listed in the patients.csv.gz file.

6.  What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, and `ethnicity`? Also report the count for each unique value of these variables. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq -c`, `wc`, and so on; skip the header line.

**admission_type:**

(possible values)

They are the possible values.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $6 }' | \
sort | uniq
```

(possible number of values)

The possible number of values is 9.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $6 }' | \
sort | uniq | wc -l
```

(count for each unique value of these variables)

They are the count for each unique value of these variables.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $6 }' | \
sort | uniq -c
```

**admission_location:**

(possible values)

They are the possible values.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $8 }' | \
sort | uniq
```

(possible number of values)

The possible number of values is 11.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $8 }' | \
sort | uniq | wc -l
```

(count for each unique value of these variables)

They are the count for each unique value of these variables.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $8 }' | \
sort | uniq -c
```

**insurance:**

(possible values)

They are the possible values.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $10 }' | \
sort | uniq
```

(possible number of values)

The possible number of values is 3.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $10 }' | \
sort | uniq | wc -l
```

(count for each unique value of these variables)

They are the count for each unique value of these variables.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $10 }' | \
sort | uniq -c
```

**race:**

(possible values)

They are the possible values.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $13 }' | \
sort | uniq
```

(possible number of values)

The possible number of values is 33.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $13 }' | \
sort | uniq | wc -l
```

(count for each unique value of these variables)

They are the count for each unique value of these variables.

```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | awk -F, 'FNR > 1 { print $13 }' | \
sort | uniq -c
```

7.  *To compress, or not to compress. That's the question.* Let's focus on the big data file `labevents.csv.gz`. Compare compressed gz file size to the uncompressed file size. Compare the run times of `zcat < ~/mimic/labevents.csv.gz | wc -l` versus `wc -l labevents.csv`. Discuss the trade off between storage and speed for big data files. (Hint: `gzip -dk < FILENAME.gz > ./FILENAME`. Remember to delete the large `labevents.csv` file after the exercise.)

```{bash}
gzip -dk < ~/mimic/hosp/labevents.csv.gz > ~/mimic/hosp/labevents.csv
```

**Compressed gz file size:**

```{bash}
ls -lh ~/mimic/hosp/labevents.csv.gz
```

**Uncompressed file size:**

```{bash}
ls -lh ~/mimic/hosp/labevents.csv
```

**Run times of compressed gz file:**

```{bash}
time zcat < ~/mimic/hosp/labevents.csv.gz | wc -l
```

**Run times of uncompressed file:**

```{bash}
time wc -l ~/mimic/hosp/labevents.csv
```

```{bash}
rm ~/mimic/hosp/labevents.csv
```

**Answer:**

Compressed gz file doesn't take up much storage space (1.8 GB), but it takes longer to run (around 20s). Uncompressed file takes up more storage space (13 GB), but it takes shorter to run (around 6s). It's a trade off between storage and speed for big data files. Note that the run times of compressed gz file and uncompressed file may vary depending on the computer.

## Q4. Who's popular in Price and Prejudice

1.  You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder.

```{bash}
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```

##### Explain what `wget -nc` does. Do **not** put this text file `pg42671.txt` in Git.

**Explanation:**

"wget" downloads files from some URL. "-nc" means only if the file doesn't already exist locally or if the local file has to be updated, the file will be downloaded.

Complete the following loop to tabulate the number of times each of the four characters is mentioned using Linux commands.

**Answer:**

The names of Elizabeth, Jane, Lydia, and Darcy were mentioned 634, 293, 171, and 418 times. Elizabeth was the most mentioned.

```{bash}
# wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt

for char in Elizabeth Jane Lydia Darcy
  do
    echo $char:
    grep -o -i $char pg42671.txt | wc -l 
  done
```

2.  What's the difference between the following two commands?

```{bash}
#| eval: false
echo 'hello, world' > test1.txt
```

and

```{bash}
#| eval: false
echo 'hello, world' >> test2.txt
```

**Answer**

**echo 'hello, world' \> test1.txt:**

This command will create or overwrite a file called "test1.txt" and write "hello, world" in it.

**echo 'hello, world' \>\> test2.txt:**

This command will append "hello, world" in the last line of the file in the existing "test2.txt" file. If the "test2.txt" file does not exist, this command makes "test2.txt" and write "hello, world" in it.

3.  Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:

```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```

Using `chmod` to make the file executable by the owner, and run

```{bash}
chmod +x middle.sh
```

```{bash}
./middle.sh pg42671.txt 20 5
```

Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script. Why do we need the first line of the shell script?

**Explanation:**

This script takes the first 20 lines of the file "pg42671.txt" and then takes the last 5 lines of the first 20 lines, which is the output.

\$1 specifies a file. \$2 specifies the end line you extract. \$3 specifies the number of lines you extract. The first line of the shell script is called "shebang" and it tells the computer which interpreter to use to execute the script.

## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`, `cal 2024`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

**cal**

This command displays a calendar of the current month.

```{bash}
cal
```

**cal 2024**

This command displays a calendar of the year 2024.

```{bash}
cal 2024
```

**cal 9 1752**

This command displays a calendar of the year 1752, September. This is unusual because September 1752 had only 19 days.

```{bash}
cal 9 1752
```

**date**

This command displays the current date and time.

```{bash}
date
```

**hostname**

This command displays the name of the host (computer).

```{bash}
hostname
```

**arch**

This command displays the architecture of the computer.

```{bash}
arch
```

**uname -a**

This command displays the operating system, kernel version, hostname, date and time of the last kernel built, the machine architecture, and so on.

```{bash}
uname -a
```

**uptime**

This command displays the current time, how long the computer has been running, how many users are currently logged on, and the system load averages for the past 1, 5, and 15 minutes.

```{bash}
uptime
```

**who am i**

This command usually displays the username, terminal, and date and time of the last log in.

```{bash}
who am i
```

**who**

This command displays the information about the currently logged in user, such as username, terminal, date, and time of the last login.

```{bash}
who
```

**w**

In the first line, this command displays the current time, how long the computer has been running, how many users are currently logged on, and the system load averages for the past 1, 5, and 15 minutes. In the subsequent lines, this command displays the information about the currently logged in user, such as username, terminal, log-in time, idle time, current process, and command-line shells.

```{bash}
w | cat -v
```

**id**

This command displays the user and group information for the current user.

```{bash}
id
```

**last \| head**

***last*** command displays the information about the last logged in users. ***head*** command is used to display the first few lines of the output. So, "last \| head" displays the information about the recent (10) last logged in users.

```{bash}
last | head
```

**echo {con,pre}{sent,fer}{s,ed}**

This command displays all the possible combinations of the words "con" or "pre" with the words "sent" or "fer" with the words "s" or "ed".

```{bash}
echo {con,pre}{sent,fer}{s,ed}
```

**time sleep 5**

This command displays the time it takes to run the command "sleep 5" by a system, user and real time.

```{bash}
time sleep 5
```

**history \| tail**

This command usually displays the last 10 commands you have run.

```{bash}
history | tail
```

## Q6. Book

1.  Git clone the repository <https://github.com/christophergandrud/Rep-Res-Book> for the book *Reproducible Research with R and RStudio* to your local machine.

**Answer:**

I did it.

![](images/Q6-1.png){width="346"}

2.  Open the project by clicking `rep-res-3rd-edition.Rproj` and compile the book by clicking `Build Book` in the `Build` panel of RStudio. (Hint: I was able to build `git_book` and `epub_book` but not `pdf_book`.)

**Answer:**

I did it.

![](images/Q6-2.png)

The point of this exercise is (1) to get the book for free and (2) to see an example how a complicated project such as a book can be organized in a reproducible way.

For grading purpose, include a screenshot of Section 4.1.5 of the book here.

**Answer:**

![](images/Q6-3.png)
